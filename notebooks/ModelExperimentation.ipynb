{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider the following five simple baseline models to provide foundational insights. These will serve as the baseline performance metrics that any subsequent machine learning models aim to beat.\n",
    "\n",
    "1. **Global Mean Rating**:\n",
    "This model predicts the global mean rating for all user-item pairs, serving as the most basic form of recommendation.\n",
    "\n",
    "2. **User Mean Rating**:\n",
    "For this model, the mean rating of each user is calculated and used to predict ratings for all items the user has not yet interacted with.\n",
    "\n",
    "3. **Item Mean Rating**:\n",
    "In contrast to the User Mean Rating, this model focuses on the mean rating of each item and uses it to predict ratings for all users.\n",
    "\n",
    "4. **User-Item Mean Rating**:\n",
    "This model takes a more nuanced approach by predicting a rating for a user-item pair as the average of the user's mean rating and the item's mean rating. The formula is:\n",
    "$$prediction = \\frac{User Mean Rating + Item Mean Rating}{2}$$\n",
    "\n",
    "5. **Weighted Mean Ratings**:\n",
    "This model employs a weighted average of the user mean and item mean ratings. The weight ( w ) can be adjusted based on domain understanding. The formula is :\n",
    "$$prediction = w \\times User Mean Rating + (1 - w) \\times Item Mean Rating, \\space where \\space 0 \\leq w \\leq 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"../data/movies_metadata_after_eda.csv\")\n",
    "ratings_df = pd.read_csv(\"../data/ratings_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>global_mean_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>item_mean_rating</th>\n",
       "      <th>user_item_mean_rating</th>\n",
       "      <th>weighted_mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>1028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1049690908</td>\n",
       "      <td>3.540256</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>3.836364</td>\n",
       "      <td>3.840404</td>\n",
       "      <td>3.841212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>665</td>\n",
       "      <td>4736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1010197684</td>\n",
       "      <td>3.540256</td>\n",
       "      <td>3.294304</td>\n",
       "      <td>3.540256</td>\n",
       "      <td>3.417280</td>\n",
       "      <td>3.392685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>4002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1167420604</td>\n",
       "      <td>3.540256</td>\n",
       "      <td>3.573684</td>\n",
       "      <td>3.318182</td>\n",
       "      <td>3.445933</td>\n",
       "      <td>3.471483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>257</td>\n",
       "      <td>1274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1348544094</td>\n",
       "      <td>3.540256</td>\n",
       "      <td>3.801370</td>\n",
       "      <td>3.791667</td>\n",
       "      <td>3.796518</td>\n",
       "      <td>3.797489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>468</td>\n",
       "      <td>6440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1296191715</td>\n",
       "      <td>3.540256</td>\n",
       "      <td>2.946196</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.423098</td>\n",
       "      <td>3.327717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp  global_mean_rating  user_mean_rating  \\\n",
       "0     128     1028     5.0  1049690908            3.540256          3.844444   \n",
       "1     665     4736     1.0  1010197684            3.540256          3.294304   \n",
       "2     120     4002     3.0  1167420604            3.540256          3.573684   \n",
       "3     257     1274     4.0  1348544094            3.540256          3.801370   \n",
       "4     468     6440     4.0  1296191715            3.540256          2.946196   \n",
       "\n",
       "   item_mean_rating  user_item_mean_rating  weighted_mean_rating  \n",
       "0          3.836364               3.840404              3.841212  \n",
       "1          3.540256               3.417280              3.392685  \n",
       "2          3.318182               3.445933              3.471483  \n",
       "3          3.791667               3.796518              3.797489  \n",
       "4          3.900000               3.423098              3.327717  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sameer.services.ml_service.ml_utils import (\n",
    "    calculate_user_item_mean_rating,\n",
    "    calculate_weighted_mean_ratings,\n",
    "    calculate_rmse,\n",
    ")\n",
    "\n",
    "test_df = calculate_user_item_mean_rating(train_df, test_df)\n",
    "test_df, best_w, best_rmse = calculate_weighted_mean_ratings(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"constant_rating\"] = 2.5\n",
    "\n",
    "user_stats = train_df.groupby(\"userId\")[\"rating\"].agg([\"mean\", \"count\"]).reset_index()\n",
    "\n",
    "DAMPING_FACTOR = 0.2\n",
    "\n",
    "test_df = test_df.merge(user_stats, on=\"userId\", how=\"left\")\n",
    "test_df[\"damped_user_mean_rating\"] = ((1 - DAMPING_FACTOR) * test_df[\"mean\"]) + (\n",
    "    DAMPING_FACTOR * test_df[\"global_mean_rating\"][0]\n",
    ")\n",
    "\n",
    "rmse_damped_user_mean = calculate_rmse(\n",
    "    test_df[\"rating\"], test_df[\"damped_user_mean_rating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_global_mean = calculate_rmse(test_df[\"rating\"], test_df[\"global_mean_rating\"])\n",
    "rmse_user_mean = calculate_rmse(test_df[\"rating\"], test_df[\"user_mean_rating\"])\n",
    "rmse_item_mean = calculate_rmse(test_df[\"rating\"], test_df[\"item_mean_rating\"])\n",
    "rmse_user_item_mean = calculate_rmse(\n",
    "    test_df[\"rating\"], test_df[\"user_item_mean_rating\"]\n",
    ")\n",
    "rmse_weighted_mean = calculate_rmse(test_df[\"rating\"], test_df[\"weighted_mean_rating\"])\n",
    "rmse_constant = calculate_rmse(test_df[\"rating\"], test_df[\"constant_rating\"])\n",
    "rmse_damped_user_mean = calculate_rmse(\n",
    "    test_df[\"rating\"], test_df[\"damped_user_mean_rating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Global Mean Rating Model: 1.06\n",
      "RMSE for User Mean Rating Model: 0.96\n",
      "RMSE for Item Mean Rating Model: 1.00\n",
      "RMSE for User-Item Mean Rating Model: 0.92\n",
      "RMSE for Weighted Mean Rating Model: 0.92, with setting the best weight is 0.60\n",
      "RMSE for Constant Model: 1.49\n",
      "RMSE for Damped User-Mean Rating Model: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE for Global Mean Rating Model: {rmse_global_mean:.2f}\")\n",
    "print(f\"RMSE for User Mean Rating Model: {rmse_user_mean:.2f}\")\n",
    "print(f\"RMSE for Item Mean Rating Model: {rmse_item_mean:.2f}\")\n",
    "print(f\"RMSE for User-Item Mean Rating Model: {rmse_user_item_mean:.2f}\")\n",
    "print(\n",
    "    f\"RMSE for Weighted Mean Rating Model: {best_rmse:.2f}, with setting the best weight is {best_w:.2f}\"\n",
    ")\n",
    "print(f\"RMSE for Constant Model: {rmse_constant:.2f}\")\n",
    "print(f\"RMSE for Damped User-Mean Rating Model: {rmse_damped_user_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In building a movie recommendation system, we start with simple models due to it's importance in understanding how well we're doing. We found out that using both the average ratings from users and movies gets the best results, with a score (RMSE) of 0.92. This score shows how accurate our predictions are â€“ the lower, the better. Models that only look at users or movies are okay, but not as good. The worst model is the one that always guesses the same rating, with a score of 1.49. These simple models help us know what to beat; any new, fancier model should score lower than 0.92 to be better.\n",
    "\n",
    "We also look at more complex models because the simple ones don't consider what each user likes. Machine learning models can give more personalized suggestions, which is better for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import (\n",
    "    Reader,\n",
    "    Dataset,\n",
    "    SVD,\n",
    "    KNNWithZScore,\n",
    "    NMF,\n",
    "    accuracy,\n",
    "    CoClustering,\n",
    ")\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "train_data = Dataset.load_from_df(train_df[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "test_data = Dataset.load_from_df(test_df[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "\n",
    "trainset = train_data.build_full_trainset()\n",
    "testset = test_data.build_full_trainset().build_testset()\n",
    "\n",
    "algorithms = [SVD, KNNWithZScore, NMF, CoClustering]\n",
    "\n",
    "param_grid = {\n",
    "    SVD: {\n",
    "        \"n_factors\": [125, 150, 175],\n",
    "        \"n_epochs\": [25, 30, 35],\n",
    "        \"lr_all\": [0.008, 0.01, 0.012],\n",
    "        \"reg_all\": [0.15, 0.2, 0.25],\n",
    "    },\n",
    "    KNNWithZScore: {\n",
    "        \"k\": [35, 40, 45],\n",
    "        \"min_k\": [1, 3, 5, 7],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"msd\", \"cosine\", \"pearson\"],\n",
    "            \"user_based\": [True, False],\n",
    "        },\n",
    "    },\n",
    "    NMF: {\n",
    "        \"n_factors\": [50, 100, 150],\n",
    "        \"n_epochs\": [20, 25, 30],\n",
    "        \"reg_pu\": [0.06, 0.08, 0.1],\n",
    "        \"reg_qi\": [0.06, 0.08, 0.1],\n",
    "    },\n",
    "    CoClustering: {\n",
    "        \"n_cltr_u\": [3, 5, 7],\n",
    "        \"n_cltr_i\": [3, 5, 7],\n",
    "        \"n_epochs\": [20, 30, 40],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model for SVD:\n",
      " <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x28aa3c350>\n",
      "Best Parameters for SVD:\n",
      " {'n_factors': 125, 'n_epochs': 35, 'lr_all': 0.012, 'reg_all': 0.15}\n",
      "Best RMSE score for SVD:\n",
      " 0.8998441491376096\n",
      "Best Model for KNNWithZScore:\n",
      " <surprise.prediction_algorithms.knns.KNNWithZScore object at 0x289354350>\n",
      "Best Parameters for KNNWithZScore:\n",
      " {'k': 45, 'min_k': 5, 'sim_options': {'name': 'msd', 'user_based': True}}\n",
      "Best RMSE score for KNNWithZScore:\n",
      " 0.9343284225878107\n",
      "Best Model for NMF:\n",
      " <surprise.prediction_algorithms.matrix_factorization.NMF object at 0x28a536dd0>\n",
      "Best Parameters for NMF:\n",
      " {'n_factors': 50, 'n_epochs': 30, 'reg_pu': 0.1, 'reg_qi': 0.1}\n",
      "Best RMSE score for NMF:\n",
      " 1.0059690699774293\n",
      "Best Model for CoClustering:\n",
      " <surprise.prediction_algorithms.co_clustering.CoClustering object at 0x288b31250>\n",
      "Best Parameters for CoClustering:\n",
      " {'n_cltr_u': 3, 'n_cltr_i': 3, 'n_epochs': 30}\n",
      "Best RMSE score for CoClustering:\n",
      " 0.9868370343277717\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "best_params = {}\n",
    "best_rmse_scores = {}\n",
    "\n",
    "for algo in algorithms:\n",
    "    gs = GridSearchCV(algo, param_grid[algo], measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "    gs.fit(train_data)\n",
    "\n",
    "    best_models[algo.__name__] = gs.best_estimator[\"rmse\"]\n",
    "    best_params[algo.__name__] = gs.best_params[\"rmse\"]\n",
    "    best_rmse_scores[algo.__name__] = gs.best_score[\"rmse\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(best_rmse_scores.keys(), best_rmse_scores.values(), color=\"blue\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Best RMSE Score\")\n",
    "plt.title(\"Best RMSE Scores by Algorithm\")\n",
    "plt.show()\n",
    "\n",
    "for algo_name, model in best_models.items():\n",
    "    print(f\"Best Model for {algo_name}:\\n\", model)\n",
    "    print(f\"Best Parameters for {algo_name}:\\n\", best_params[algo_name])\n",
    "    print(f\"Best RMSE score for {algo_name}:\\n\", best_rmse_scores[algo_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Algorithm: SVD\n",
      "Best Parameters: {'n_factors': 125, 'n_epochs': 35, 'lr_all': 0.012, 'reg_all': 0.15}\n",
      "Best RMSE score: 0.8998441491376096\n"
     ]
    }
   ],
   "source": [
    "best_algo = min(best_rmse_scores, key=best_rmse_scores.get)\n",
    "\n",
    "print(f\"Best Algorithm: {best_algo}\")\n",
    "print(f\"Best Parameters: {best_params[best_algo]}\")\n",
    "print(f\"Best RMSE score: {best_rmse_scores[best_algo]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "SVD: Achieved an RMSE score of `0.897`\n",
    "KNNWithZScore: Registered an RMSE score of `0.929`\n",
    "NMF: Posted an RMSE score of `1.002`\n",
    "\n",
    "SVD outperformed the rest, so we will be going with it with the following parameters: `Best Parameters: {'n_factors': 150, 'n_epochs': 35, 'lr_all': 0.01, 'reg_all': 0.15}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8860\n",
      "MAE:  0.6828\n",
      "FCP:  0.6602\n",
      "Evaluation Metrics:\n",
      "RMSE score: 0.8860001901862163\n",
      "MAE score: 0.6827820491582219\n",
      "FCP score: 0.6602473443058717\n"
     ]
    }
   ],
   "source": [
    "best_algo_name = min(best_rmse_scores, key=best_rmse_scores.get)\n",
    "best_algo_model = best_models[best_algo_name]\n",
    "\n",
    "best_algo_model.fit(trainset)\n",
    "\n",
    "predictions = best_algo_model.test(testset)\n",
    "\n",
    "rmse_score = accuracy.rmse(predictions)\n",
    "\n",
    "mae_score = accuracy.mae(predictions)\n",
    "fcp_score = accuracy.fcp(predictions)\n",
    "\n",
    "print(f\"Evaluation Metrics:\")\n",
    "print(f\"RMSE score: {rmse_score}\")\n",
    "print(f\"MAE score: {mae_score}\")\n",
    "print(f\"FCP score: {fcp_score}\")\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df = predictions_df.rename(\n",
    "    columns={\"uid\": \"userId\", \"iid\": \"movieId\", \"r_ui\": \"actual\", \"est\": \"predicted\"}\n",
    ")\n",
    "predictions_df[\"error\"] = np.abs(predictions_df[\"actual\"] - predictions_df[\"predicted\"])\n",
    "\n",
    "predictions_df.to_csv(\"./dump/predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"./pickels/best_svd_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_algo_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning model achieved an RMSE of 0.897 on training data and 0.8848 on test data, indicating robustness and good generalization. It outperformed baseline models (User-Item and Weighted Mean Rating Models with an RMSE of 0.92), demonstrating the effectiveness of a complex algorithm in the recommendation system. The model is suitable for real-world deployment due to its strong performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `Weighted Rating` which calcuates based on both the popularity and user ratings.\n",
    "\n",
    "By blending these two factors, we aim to suggest movies that are both high-quality and widely liked.\n",
    "\n",
    "Importantly, this method can also be combined with other recommendation techniques to create a more advanced, hybrid system. In this section, we calculate a weighted rating for each movie in the dataset. The steps are as follows:\n",
    "\n",
    "- Data Filtering: We start by selecting movies that have non-null values for both vote_average and vote_count.\n",
    "\n",
    "- Rating Metrics: We define the following variables to use in the formula:\n",
    "    - ( R ): Average rating for the movie\n",
    "    - ( v ): Number of votes for the movie\n",
    "    - ( m ): Minimum votes required (90th percentile)\n",
    "    - ( C ): The mean vote across the entire dataset\n",
    "\n",
    "- Weighted Rating Formula: We use the IMDB formula to calculate the weighted rating for each movie.\n",
    "$$Weighted Rating = \\frac{R\\times v + C \\times m}{v+m}$$\n",
    "\n",
    "- Feature Scaling: We then normalize the popularity and weighted_average columns using MinMax scaling.\n",
    "\n",
    "A score is calculated for each movie as a weighted sum of the normalized weighted_average and popularity. Specifically, it's 40% weighted_average and 60% popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = movies_df[\"vote_average\"]\n",
    "v = movies_df[\"vote_count\"]\n",
    "m = movies_df[\"vote_count\"].quantile(0.9)\n",
    "C = movies_df[\"vote_average\"].mean()\n",
    "movies_df[\"weighted_average\"] = (R * v + C * m) / (v + m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>weighted_average</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211672</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574825</td>\n",
       "      <td>0.829930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297762</th>\n",
       "      <td>0.537613</td>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.616294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321612</th>\n",
       "      <td>0.524675</td>\n",
       "      <td>0.655367</td>\n",
       "      <td>0.576952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177572</th>\n",
       "      <td>0.390602</td>\n",
       "      <td>0.856364</td>\n",
       "      <td>0.576907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0.257449</td>\n",
       "      <td>0.960073</td>\n",
       "      <td>0.538499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339403</th>\n",
       "      <td>0.416507</td>\n",
       "      <td>0.721434</td>\n",
       "      <td>0.538478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283995</th>\n",
       "      <td>0.338511</td>\n",
       "      <td>0.813503</td>\n",
       "      <td>0.528508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.224968</td>\n",
       "      <td>0.962900</td>\n",
       "      <td>0.520141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210577</th>\n",
       "      <td>0.282748</td>\n",
       "      <td>0.875895</td>\n",
       "      <td>0.520007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293660</th>\n",
       "      <td>0.343132</td>\n",
       "      <td>0.780225</td>\n",
       "      <td>0.517969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  weighted_average     score\n",
       "id                                            \n",
       "211672    1.000000          0.574825  0.829930\n",
       "297762    0.537613          0.734315  0.616294\n",
       "321612    0.524675          0.655367  0.576952\n",
       "177572    0.390602          0.856364  0.576907\n",
       "680       0.257449          0.960073  0.538499\n",
       "339403    0.416507          0.721434  0.538478\n",
       "283995    0.338511          0.813503  0.528508\n",
       "155       0.224968          0.962900  0.520141\n",
       "210577    0.282748          0.875895  0.520007\n",
       "293660    0.343132          0.780225  0.517969"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(movies_df[[\"popularity\", \"weighted_average\"]])\n",
    "\n",
    "weighted_df = pd.DataFrame(scaled, columns=[\"popularity\", \"weighted_average\"])\n",
    "weighted_df.index = movies_df[\"id\"]\n",
    "\n",
    "weighted_df[\"score\"] = (\n",
    "    weighted_df[\"weighted_average\"] * 0.4 + weighted_df[\"popularity\"] * 0.6\n",
    ")\n",
    "\n",
    "weighted_df_sorted = weighted_df.sort_values(by=\"score\", ascending=False)\n",
    "weighted_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find movies that closely match a user's preferred film, our recommendation model employs Cosine Similarity, a type of content-based filtering approach. This method calculates similarity scores for each pair of movies in our database by considering various attributes such as keywords, genre, cast, and director. These attributes, collectively termed as \"content,\" help the model to quantify how similar two movies are. If the attributes closely match, the movies are considered similar. The model then sorts these calculated scores and recommends the top 10 movies most similar to the user's chosen film. The underlying idea is that if a user enjoys a particular movie, they are likely to appreciate similar ones as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4v/n05vgwdj65b8dkvc11yd9bzr0000gn/T/ipykernel_69829/1889371782.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  movies_df[\"bag_of_words\"].fillna(\"-\", inplace=True)\n",
      "/var/folders/4v/n05vgwdj65b8dkvc11yd9bzr0000gn/T/ipykernel_69829/1889371782.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  movies_df[\"director\"].fillna(\"-\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "movies_df[\"bag_of_words\"].fillna(\"-\", inplace=True)\n",
    "movies_df[\"director\"].fillna(\"-\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count = CountVectorizer(stop_words=\"english\")\n",
    "count_matrix = count.fit_transform(movies_df[\"bag_of_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.reset_index()\n",
    "indices = pd.Series(movies_df.index, index=movies_df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim):\n",
    "    # TODO: add fuzzy search to match the title\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies_df[\"title\"].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12535      The Dark Knight\n",
       "10164        Batman Begins\n",
       "9265                Shiner\n",
       "9828       Amongst Friends\n",
       "7727              Mitchell\n",
       "516      Romeo Is Bleeding\n",
       "11405         The Prestige\n",
       "24004            Quicksand\n",
       "24945             Deadfall\n",
       "40973                 Sara\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"The Dark Knight Rises\", sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22798                           Behind Enemy Lines\n",
       "2524     Star Wars: Episode I - The Phantom Menace\n",
       "8690                              Gamera vs. Jiger\n",
       "10166                         Godzilla: Final Wars\n",
       "18104               Prisoners of the Lost Universe\n",
       "22701                             Gamera vs. Viras\n",
       "22815                            Gamera vs. Guiron\n",
       "25196                               Jurassic World\n",
       "28472                             Gamera vs. Zigra\n",
       "19410                           Bells of Innocence\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Dune\", sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42477                 Daishizen no MajÅ«: Bagi\n",
       "9645                                  Wizards\n",
       "16446                  The Return of the King\n",
       "37536               The Life of Guskou Budori\n",
       "16524               Cirque du Soleil: Varekai\n",
       "16583                         The Fern Flower\n",
       "24329                   How Wang-Fo Was Saved\n",
       "28872                              The Mascot\n",
       "30169                                 My Love\n",
       "32283    Monster High: Scaris City of Frights\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"The Lord of the Rings\", sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sameer.services.ml_service.ml_utils import load_pickle_model\n",
    "\n",
    "model = load_pickle_model(\"./pickels/best_svd_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted hybrid rating for userId=1 and movieId=500 is: 1.793085232585049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mamdouh/Developer/filmora/Sameer/services/ml_service/ml_utils.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies[\"est\"] = similar_movies[\"id\"].apply(\n"
     ]
    }
   ],
   "source": [
    "from Sameer.services.ml_service.ml_utils import hybrid_predicted_rating\n",
    "\n",
    "predicted_rating = hybrid_predicted_rating(\n",
    "    userId=1,\n",
    "    movieId=500,\n",
    "    model=model,\n",
    "    similarity_matrix=sim_mat,\n",
    "    movies_df=movies_df,\n",
    "    weighted_df=weighted_df,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The predicted hybrid rating for userId=1 and movieId=500 is: {predicted_rating}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "movies_df[\"genres\"] = movies_df[\"genres\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending Movies for Old Users\n",
    "\n",
    "In this section, we will generate movie recommendations for users through our Hybrid Movie Recommender System. The system requires a user ID and follows a two-step process:\n",
    "\n",
    "1. Collaborative Filtering: The system predicts movie ratings based on the user's past behavior using collaborative filtering techniques.\n",
    "\n",
    "2. Content-Based Filtering: The system finds movies similar to the user's last watched movie using content-based filtering. It considers attributes such as keywords, genre, cast, and director to quantify the similarity between movies.\n",
    "\n",
    "The Hybrid Movie Recommender System combines the recommendations from both collaborative filtering and content-based filtering. It assigns equal weight to each set of recommendations and generates a final list of the top 10 recommended movies. This hybrid approach aims to provide more accurate and personalized movie suggestions for old users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID 30825.0 not found in movies_df.\n",
      "Recommended movies for user 235: [920.0, 4326.0, 318.0, 4973.0, 4880.0, 6187.0, 4226.0, 1207.0, 50.0, 2858.0]\n",
      "Recommended Movies:-\n",
      "\tTitle: Dry Cleaning (1997), Genres: drama, Director: annefontaine\n",
      "\tTitle: The Million Dollar Hotel (2000), Genres: drama, thriller, Director: wimwenders\n",
      "\tTitle: Under the Sand (2000), Genres: drama, mystery, Director: franÃ§oisozon\n",
      "\tTitle: Herr Lehmann (2003), Genres: comedy, drama, Director: leanderhauÃŸmann\n",
      "\tTitle: Cars (2006), Genres: animation, adventure, comedy, Director: johnlasseter\n",
      "\tTitle: Nichts als Gespenster (2006), Genres: comedy, drama, Director: martingypkens\n",
      "\tTitle: Shriek If You Know What I Did Last Friday the Thirteenth (2000), Genres: comedy, Director: johnblanchard\n"
     ]
    }
   ],
   "source": [
    "def get_weighted_scores(movie_ids, weighted_df):\n",
    "    \"\"\"\n",
    "    Fetches the weighted scores for a list of movie IDs.\n",
    "\n",
    "    Parameters:\n",
    "    - movie_ids (list): A list of movie IDs for which to fetch the weighted scores.\n",
    "    - weighted_df (pandas.DataFrame): The weighted DataFrame containing weighted scores.\n",
    "\n",
    "    Returns:\n",
    "    - weighted_scores (dict): A dictionary mapping movie IDs to their corresponding weighted scores.\n",
    "    \"\"\"\n",
    "    weighted_df = weighted_df.loc[~weighted_df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    weighted_scores = {\n",
    "        movie_id: (\n",
    "            weighted_df.loc[movie_id][\"score\"] if movie_id in weighted_df.index else 0\n",
    "        )\n",
    "        for movie_id in movie_ids\n",
    "    }\n",
    "\n",
    "    return weighted_scores\n",
    "\n",
    "\n",
    "def show_movie_details(movie_ids, movies_df):\n",
    "    \"\"\"\n",
    "    Display the details of recommended movies based on the specified movie IDs.\n",
    "\n",
    "    Args:\n",
    "        movie_ids (list): A list of movie IDs to filter the DataFrame.\n",
    "        movies_df (pandas.DataFrame): The DataFrame containing movie details.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the movies_df DataFrame does not include the required columns.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    required_columns = [\"id\", \"title\", \"year\", \"genres\", \"director\"]\n",
    "    if not all(column in movies_df.columns for column in required_columns):\n",
    "        raise ValueError(\n",
    "            f\"movies_df must include the following columns: {required_columns}\"\n",
    "        )\n",
    "\n",
    "    details_df = movies_df.loc[\n",
    "        movies_df[\"id\"].isin(movie_ids), [\"title\", \"year\", \"genres\", \"director\"]\n",
    "    ]\n",
    "\n",
    "    print(\"Recommended Movies:-\")\n",
    "    for _, row in details_df.iterrows():\n",
    "        genres = (\n",
    "            \", \".join(row[\"genres\"])\n",
    "            if isinstance(row[\"genres\"], list)\n",
    "            else row[\"genres\"]\n",
    "        )\n",
    "        print(\n",
    "            f\"\\tTitle: {row['title']} ({row['year']}), Genres: {genres}, Director: {row['director']}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_user_rating_predictions(user_ratings):\n",
    "    \"\"\"\n",
    "    Get predictions for user ratings.\n",
    "\n",
    "    Args:\n",
    "        user_ratings (pandas.DataFrame): DataFrame containing user ratings with columns \"userId\" and \"movieId\".\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples containing movieId and corresponding predicted ratings.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for _, row in user_ratings.iterrows():\n",
    "        pred = model.predict(row[\"userId\"], row[\"movieId\"]).est\n",
    "        predictions.append((row[\"movieId\"], pred))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_top_collab_movies(predictions, n):\n",
    "    \"\"\"\n",
    "    Returns a list of the top n movies based on the predictions.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (list): A list of tuples containing movie names and their corresponding prediction values.\n",
    "    n (int): The number of top movies to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of the top n movie names.\n",
    "\n",
    "    \"\"\"\n",
    "    return [x[0] for x in sorted(predictions, key=lambda x: x[1], reverse=True)[:n]]\n",
    "\n",
    "\n",
    "def get_similar_movies(last_watched_movieId, n):\n",
    "    \"\"\"\n",
    "    Get a list of similar movies based on the last watched movie.\n",
    "\n",
    "    Parameters:\n",
    "    last_watched_movieId (int): The ID of the last watched movie.\n",
    "    n (int): The number of similar movies to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of movie IDs of similar movies.\n",
    "\n",
    "    \"\"\"\n",
    "    if last_watched_movieId in movies_df[\"id\"].values:\n",
    "        watched_movie_idx = movies_df[movies_df[\"id\"] == last_watched_movieId].index[0]\n",
    "        similar_movies = list(enumerate(sim_mat[watched_movie_idx]))\n",
    "        sorted_similar_movies = sorted(\n",
    "            similar_movies, key=lambda x: x[1], reverse=True\n",
    "        )[1 : n + 1]\n",
    "        return [movies_df.iloc[i[0]][\"id\"] for i in sorted_similar_movies]\n",
    "    else:\n",
    "        print(f\"Movie ID {last_watched_movieId} not found in movies_df.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def combine_scores(collab_weighted_scores, content_weighted_scores):\n",
    "    \"\"\"\n",
    "    Combines collaborative and content-based weighted scores for movies.\n",
    "\n",
    "    Parameters:\n",
    "    - collab_weighted_scores (dict): A dictionary containing movie IDs as keys and collaborative weighted scores as values.\n",
    "    - content_weighted_scores (dict): A dictionary containing movie IDs as keys and content-based weighted scores as values.\n",
    "\n",
    "    Returns:\n",
    "    - combined_scores (dict): A dictionary containing movie IDs as keys and combined scores as values, where the combined score is calculated as the sum of 0.5 times the collaborative weighted score and 0.5 times the content-based weighted score.\n",
    "    \"\"\"\n",
    "    combined_scores = {}\n",
    "    for movie_id, score in collab_weighted_scores.items():\n",
    "        combined_scores[movie_id] = combined_scores.get(movie_id, 0) + 0.5 * score\n",
    "    for movie_id, score in content_weighted_scores.items():\n",
    "        combined_scores[movie_id] = combined_scores.get(movie_id, 0) + 0.5 * score\n",
    "    return combined_scores\n",
    "\n",
    "\n",
    "def hybrid_recommendation(user_id, n=10):\n",
    "    \"\"\"\n",
    "    Generates hybrid movie recommendations for a given user.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): The ID of the user for whom recommendations are generated.\n",
    "        n (int, optional): The number of recommendations to generate. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of movie IDs representing the top recommended movies for the user.\n",
    "    \"\"\"\n",
    "    user_ratings = ratings_df[ratings_df[\"userId\"] == user_id]\n",
    "    predictions = get_user_rating_predictions(user_ratings)\n",
    "    top_collab_movies = get_top_collab_movies(predictions, n)\n",
    "    last_watched_movieId = user_ratings.iloc[-1][\"movieId\"]\n",
    "    top_content_movies = get_similar_movies(last_watched_movieId, n)\n",
    "    collab_weighted_scores = get_weighted_scores(top_collab_movies, weighted_df)\n",
    "    content_weighted_scores = get_weighted_scores(top_content_movies, weighted_df)\n",
    "    combined_scores = combine_scores(collab_weighted_scores, content_weighted_scores)\n",
    "    sorted_movies = sorted(\n",
    "        combined_scores.keys(), key=lambda x: combined_scores[x], reverse=True\n",
    "    )\n",
    "    return sorted_movies[:n]\n",
    "\n",
    "\n",
    "user_id = 235\n",
    "recommended_movies = hybrid_recommendation(user_id)\n",
    "print(f\"Recommended movies for user {user_id}: {recommended_movies}\")\n",
    "show_movie_details(recommended_movies, movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending Movies for New Users\n",
    "\n",
    "In this section, we explore strategies to recommend movies to new users who have no historical data. We use two different approaches to tackle this issue:\n",
    "\n",
    "To address the 'cold start' problem, we recommend top-rated and recent movies to new users. This approach utilizes a DataFrame of movie IDs and their weighted scores to generate a list of top n movies from the last min_year years. The recommendations are sorted by a score that combines both popularity and user ratings. The function is flexible, allowing you to specify the number of recommendations and the time frame for recent movies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Movies:-\n",
      "\tTitle: Pirates of the Caribbean: Dead Men Tell No Tales (2017), Genres: adventure, action, fantasy, Director: joachimrÃ¸nning\n",
      "\tTitle: Deadpool (2016), Genres: action, adventure, comedy, Director: timmiller\n",
      "\tTitle: Guardians of the Galaxy Vol. 2 (2017), Genres: action, adventure, comedy, Director: jamesgunn\n",
      "\tTitle: Captain America: Civil War (2016), Genres: adventure, action, sciencefiction, Director: anthonyrusso\n",
      "\tTitle: Wonder Woman (2017), Genres: action, adventure, fantasy, Director: pattyjenkins\n",
      "\tTitle: Your Name. (2016), Genres: romance, animation, drama, Director: makotoshinkai\n",
      "\tTitle: Logan (2017), Genres: action, drama, sciencefiction, Director: jamesmangold\n",
      "\tTitle: Beauty and the Beast (2017), Genres: family, fantasy, romance, Director: billcondon\n",
      "\tTitle: Baby Driver (2017), Genres: action, crime, Director: edgarwright\n",
      "\tTitle: War for the Planet of the Apes (2017), Genres: drama, sciencefiction, war, Director: mattreeves\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def recommend_for_new_user_top_rating_movies(\n",
    "    weighted_df, movies_df, top_n=10, min_year=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Recommend the top n movies for a new user based on weighted rating scores.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing movie IDs and their weighted scores.\n",
    "    n (int): Number of top movies to recommend.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Top n recommended movies for a new user.\n",
    "    \"\"\"\n",
    "    current_year = datetime.now().year\n",
    "    recent_movies_filter = movies_df[\"year\"].fillna(0).astype(int) >= (\n",
    "        current_year - min_year\n",
    "    )\n",
    "    recent_movies_df = movies_df[recent_movies_filter]\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        weighted_df, recent_movies_df[[\"id\", \"year\"]], on=\"id\", how=\"inner\"\n",
    "    )\n",
    "    top_movies_df = merged_df.sort_values(by=\"score\", ascending=False).head(top_n)\n",
    "\n",
    "    return top_movies_df\n",
    "\n",
    "\n",
    "top_movies = recommend_for_new_user_top_rating_movies(\n",
    "    weighted_df, movies_df[[\"id\", \"year\"]], top_n=10, min_year=8\n",
    ")\n",
    "show_movie_details(top_movies[\"id\"], movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another approach for the cold start problem\n",
    "\n",
    "To address the 'cold start' problem for new users, we can recommend top-rated movies in various genres. This approach provides genre-specific lists of top movies from the last `min_year` years. By offering genre-specific recommendations, new users can immediately find movies aligned with their preferences.\n",
    "\n",
    "the unique geners = ['mystery', 'action', 'comedy', 'foreign', 'war', 'tvmovie', 'fantasy', 'adventure', 'thriller', 'history', 'documentary', 'horror', 'sciencefiction', 'western', 'romance', 'family', 'animation', 'crime', 'drama', 'music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sciencefiction\n",
      "Recommended Movies:-\n",
      "\tTitle: Guardians of the Galaxy (2014), Genres: action, sciencefiction, adventure, Director: jamesgunn\n",
      "\tTitle: Captain America: Civil War (2016), Genres: adventure, action, sciencefiction, Director: anthonyrusso\n",
      "\tTitle: War for the Planet of the Apes (2017), Genres: drama, sciencefiction, war, Director: mattreeves\n",
      "documentary\n",
      "Recommended Movies:-\n",
      "\tTitle: Citizenfour (2014), Genres: documentary, Director: laurapoitras\n",
      "\tTitle: Going Clear: Scientology and the Prison of Belief (2015), Genres: documentary, Director: alexgibney\n",
      "\tTitle: Amy (2015), Genres: documentary, music, Director: asifkapadia\n",
      "comedy\n",
      "Recommended Movies:-\n",
      "\tTitle: Deadpool (2016), Genres: action, adventure, comedy, Director: timmiller\n",
      "\tTitle: Guardians of the Galaxy Vol. 2 (2017), Genres: action, adventure, comedy, Director: jamesgunn\n",
      "\tTitle: Inside Out (2015), Genres: drama, comedy, animation, Director: petedocter\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def recommend_for_new_user_by_genre(\n",
    "    weighted_df,\n",
    "    movies_df,\n",
    "    target_genres,\n",
    "    top_n=10,\n",
    "    recent_years_threshold=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Recommend the top N movies for a new user based on weighted rating scores within specified genres,\n",
    "    considering movies released within a defined recent year threshold.\n",
    "\n",
    "    Parameters:\n",
    "    weighted_scores_df (DataFrame): DataFrame containing movie IDs and their weighted scores.\n",
    "    movies_details_df (DataFrame): DataFrame containing movie IDs, genres, and release years.\n",
    "    target_genres (list): List of genres to consider for recommendations.\n",
    "    top_n (int): Number of top movies to recommend for each genre.\n",
    "    recent_years_threshold (int): Number of recent years to consider for movie recommendations.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with genres as keys and DataFrames of top N recommended movies for each genre as values.\n",
    "    \"\"\"\n",
    "    recommendations = {}\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    movies_details_df = movies_df.copy()\n",
    "    movies_details_df[\"year\"] = movies_details_df[\"year\"].fillna(0).astype(int)\n",
    "\n",
    "    recent_movies_df = movies_details_df[\n",
    "        movies_details_df[\"year\"] >= (current_year - recent_years_threshold)\n",
    "    ]\n",
    "\n",
    "    for genre in target_genres:\n",
    "        genre_filtered_df = recent_movies_df[\n",
    "            recent_movies_df[\"genres\"].apply(\n",
    "                lambda genres: genre in genres if genres else False\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        genre_with_scores_df = pd.merge(\n",
    "            weighted_df, genre_filtered_df[[\"id\", \"year\"]], on=\"id\", how=\"inner\"\n",
    "        )\n",
    "\n",
    "        top_movies_for_genre = genre_with_scores_df.sort_values(\n",
    "            by=\"score\", ascending=False\n",
    "        ).head(top_n)\n",
    "\n",
    "        recommendations[genre] = top_movies_for_genre\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "genres_list = [\"sciencefiction\", \"documentary\", \"comedy\"]\n",
    "\n",
    "top_movies_by_genre = recommend_for_new_user_by_genre(\n",
    "    weighted_df, movies_df, genres_list, top_n=3, recent_years_threshold=10\n",
    ")\n",
    "for genre in genres_list:\n",
    "    print(genre)\n",
    "    show_movie_details(top_movies_by_genre[genre][\"id\"], movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
